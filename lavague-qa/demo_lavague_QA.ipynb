{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le6eYfy0xVZF"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "LaVague QA is a command-line tool that turns Gherkin test specifications into ready-to-use Pytest code for web applications. Built on the LaVague open-source framework, it automates the creation and maintenance of automated tests.\n",
        "\n",
        "\n",
        "### How it works\n",
        "\n",
        "1. Write test scenarios in natural language using Gherkin.\n",
        "2. Run LaVague QA to automatically generate the corresponding Pytest code.\n",
        "3. Execute tests or regenerate them as your website evolves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVRXPVjkxVg2"
      },
      "source": [
        "# Installation\n",
        "\n",
        "## Start by installing\n",
        "- `lavague-qa`\n",
        "- `pytest-bdd`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gp_X6hpfDPX",
        "outputId": "4b8c2629-c505-4257-d735-b14fd9a7138d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lavague-qa\n",
            "  Downloading lavague_qa-0.0.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pytest-bdd\n",
            "  Downloading pytest_bdd-7.2.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from lavague-qa) (8.1.7)\n",
            "Collecting gherkin-official<29.0.0,>=28.0.0 (from lavague-qa)\n",
            "  Downloading gherkin_official-28.0.0-py3-none-any.whl.metadata (541 bytes)\n",
            "Collecting lavague-core<0.3.0,>=0.2.28 (from lavague-qa)\n",
            "  Downloading lavague_core-0.2.32-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting lavague-drivers-selenium<0.3.0,>=0.2.6 (from lavague-qa)\n",
            "  Downloading lavague_drivers_selenium-0.2.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting lavague-tests<0.0.5,>=0.0.4 (from lavague-qa)\n",
            "  Downloading lavague_tests-0.0.4-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting yaspin<4.0.0,>=3.0.2 (from lavague-qa)\n",
            "  Downloading yaspin-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting Mako (from pytest-bdd)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest-bdd) (24.1)\n",
            "Collecting parse (from pytest-bdd)\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting parse-type (from pytest-bdd)\n",
            "  Downloading parse_type-0.6.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pytest>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest-bdd) (7.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pytest-bdd) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from lavague-core<0.3.0,>=0.2.28->lavague-qa) (6.0.1)\n",
            "Requirement already satisfied: ipython<8.0.0,>=7.34.0 in /usr/local/lib/python3.10/dist-packages (from lavague-core<0.3.0,>=0.2.28->lavague-qa) (7.34.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /usr/local/lib/python3.10/dist-packages (from lavague-core<0.3.0,>=0.2.28->lavague-qa) (4.23.0)\n",
            "Collecting langchain<0.2.0,>=0.1.20 (from lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index==0.10.56 (from lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index-0.10.56-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-retrievers-bm25<0.2.0,>=0.1.3 (from lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_retrievers_bm25-0.1.5-py3-none-any.whl.metadata (700 bytes)\n",
            "Collecting lxml<6.0.0,>=5.1.1 (from lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting lxml-html-clean<0.2.0,>=0.1.1 (from lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading lxml_html_clean-0.1.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.0.8)\n",
            "Collecting seaborn<0.14.0,>=0.13.2 (from lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting tenacity<8.4.0,>=8.2.0 (from lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting trafilatura<2.0.0,>=1.9.0 (from lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading trafilatura-1.12.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core==0.10.56 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_core-0.10.56-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_llms_openai-0.1.27-py3-none-any.whl.metadata (610 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_readers_file-0.1.32-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.26.4)\n",
            "Collecting openai>=1.1.0 (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading openai-1.38.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2.31.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (4.66.4)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.16.0)\n",
            "Collecting selenium<5.0.0,>=4.18.1 (from lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa)\n",
            "  Downloading selenium-4.23.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.0->pytest-bdd) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.0->pytest-bdd) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.0->pytest-bdd) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.0->pytest-bdd) (2.0.1)\n",
            "Collecting termcolor==2.3.0 (from yaspin<4.0.0,>=3.0.2->lavague-qa)\n",
            "  Downloading termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->pytest-bdd) (2.1.5)\n",
            "Requirement already satisfied: six>=1.15 in /usr/local/lib/python3.10/dist-packages (from parse-type->pytest-bdd) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.23.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.23.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.23.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.23.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (0.19.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa) (4.0.3)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading langsmith-0.1.96-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2.8.2)\n",
            "Collecting rank-bm25<0.3.0,>=0.2.2 (from llama-index-retrievers-bm25<0.2.0,>=0.1.3->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn<0.14.0,>=0.13.2->lavague-core<0.3.0,>=0.2.28->lavague-qa) (3.7.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa)\n",
            "  Downloading trio-0.26.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa) (2024.7.4)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa) (1.8.0)\n",
            "Collecting courlan>=1.2.0 (from trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading courlan-1.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting htmldate>=1.8.1 (from trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading htmldate-1.8.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting justext>=3.0.1 (from trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading jusText-3.0.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: charset-normalizer>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (3.3.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.9.4)\n",
            "Requirement already satisfied: babel>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from courlan>=1.2.0->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2.15.0)\n",
            "Collecting tld>=0.13 (from courlan>=1.2.0->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading tld-0.13-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting dateparser>=1.1.2 (from htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading dateparser-1.2.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (0.8.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting packaging (from pytest-bdd)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_cloud-0.0.11-py3-none-any.whl.metadata (751 bytes)\n",
            "INFO: pip is looking at multiple versions of llama-index-llms-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_llms_openai-0.1.26-py3-none-any.whl.metadata (610 bytes)\n",
            "INFO: pip is looking at multiple versions of llama-index-program-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<0.14.0,>=0.13.2->lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<0.14.0,>=0.13.2->lavague-core<0.3.0,>=0.2.28->lavague-qa) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<0.14.0,>=0.13.2->lavague-core<0.3.0,>=0.2.28->lavague-qa) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<0.14.0,>=0.13.2->lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<0.14.0,>=0.13.2->lavague-core<0.3.0,>=0.2.28->lavague-qa) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2024.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2.20.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (3.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (3.0.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.6->lavague-qa) (1.7.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2.5)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (2024.5.15)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.28->lavague-qa) (5.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.4.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa) (1.7.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core<0.3.0,>=0.2.28->lavague-qa)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading lavague_qa-0.0.3-py3-none-any.whl (10 kB)\n",
            "Downloading pytest_bdd-7.2.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gherkin_official-28.0.0-py3-none-any.whl (36 kB)\n",
            "Downloading lavague_core-0.2.32-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.10.56-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_core-0.10.56-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lavague_drivers_selenium-0.2.12-py3-none-any.whl (9.1 kB)\n",
            "Downloading lavague_tests-0.0.4-py3-none-any.whl (9.1 kB)\n",
            "Downloading yaspin-3.0.2-py3-none-any.whl (18 kB)\n",
            "Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading parse_type-0.6.2-py2.py3-none-any.whl (26 kB)\n",
            "Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_retrievers_bm25-0.1.5-py3-none-any.whl (2.8 kB)\n",
            "Downloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.1.1-py3-none-any.whl (11 kB)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.23.1-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading trafilatura-1.12.0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading courlan-1.3.0-py3-none-any.whl (33 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading htmldate-1.8.1-py3-none-any.whl (31 kB)\n",
            "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Downloading jusText-3.0.1-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.8/837.8 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading langsmith-0.1.96-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
            "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.1.26-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.1.32-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading trio-0.26.1-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.7/475.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading llama_cloud-0.0.11-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.38.0-py3-none-any.whl (335 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.9/335.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: striprtf, parse, gherkin-official, dirtyjson, tld, termcolor, tenacity, rank-bm25, pypdf, parse-type, packaging, outcome, orjson, mypy-extensions, Mako, lxml, jsonpointer, jedi, h11, deprecated, yaspin, wsproto, typing-inspect, trio, tiktoken, marshmallow, lxml-html-clean, jsonpatch, httpcore, dateparser, courlan, trio-websocket, seaborn, pytest-bdd, langsmith, httpx, htmldate, dataclasses-json, selenium, openai, llama-cloud, langchain-core, justext, trafilatura, llama-index-legacy, llama-index-core, langchain-text-splitters, langchain-community, llama-parse, llama-index-retrievers-bm25, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index, lavague-core, lavague-drivers-selenium, lavague-tests, lavague-qa\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.4.0\n",
            "    Uninstalling termcolor-2.4.0:\n",
            "      Successfully uninstalled termcolor-2.4.0\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.9.4\n",
            "    Uninstalling lxml-4.9.4:\n",
            "      Successfully uninstalled lxml-4.9.4\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.13.1\n",
            "    Uninstalling seaborn-0.13.1:\n",
            "      Successfully uninstalled seaborn-0.13.1\n",
            "Successfully installed Mako-1.3.5 courlan-1.3.0 dataclasses-json-0.6.7 dateparser-1.2.0 deprecated-1.2.14 dirtyjson-1.0.8 gherkin-official-28.0.0 h11-0.14.0 htmldate-1.8.1 httpcore-1.0.5 httpx-0.27.0 jedi-0.19.1 jsonpatch-1.33 jsonpointer-3.0.0 justext-3.0.1 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.2 langsmith-0.1.96 lavague-core-0.2.32 lavague-drivers-selenium-0.2.12 lavague-qa-0.0.3 lavague-tests-0.0.4 llama-cloud-0.0.11 llama-index-0.10.56 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.56 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.26 llama-index-multi-modal-llms-openai-0.1.8 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.32 llama-index-readers-llama-parse-0.1.6 llama-index-retrievers-bm25-0.1.5 llama-parse-0.4.9 lxml-5.2.2 lxml-html-clean-0.1.1 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.38.0 orjson-3.10.6 outcome-1.3.0.post0 packaging-23.2 parse-1.20.2 parse-type-0.6.2 pypdf-4.3.1 pytest-bdd-7.2.0 rank-bm25-0.2.2 seaborn-0.13.2 selenium-4.23.1 striprtf-0.0.26 tenacity-8.3.0 termcolor-2.3.0 tiktoken-0.7.0 tld-0.13 trafilatura-1.12.0 trio-0.26.1 trio-websocket-0.11.1 typing-inspect-0.9.0 wsproto-1.2.0 yaspin-3.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install lavague-qa pytest-bdd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGyjrXB60H2K"
      },
      "source": [
        "### Get the `OPENAI_API_KEY` from the environment.\n",
        "\n",
        "Add your key to the secrets tab if you're running in colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izuMPtAgfV9z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "else:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlAiObzVxqb-"
      },
      "source": [
        "# 1. Define test scenario\n",
        "We fetch a `.feature` file from the LaVague repository and display it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kf0Wa9PfFWW",
        "outputId": "92ff7bf9-c5f3-41a4-80db-b275faf6b6f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-08-05 07:11:30--  https://raw.githubusercontent.com/lavague-ai/LaVague/rework-qa-automation-example/lavague-qa/features/demo_wikipedia.feature\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 426 [text/plain]\n",
            "Saving to: ‘demo_wikipedia.feature’\n",
            "\n",
            "\rdemo_wikipedia.feat   0%[                    ]       0  --.-KB/s               \rdemo_wikipedia.feat 100%[===================>]     426  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-05 07:11:30 (8.91 MB/s) - ‘demo_wikipedia.feature’ saved [426/426]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/lavague-ai/LaVague/main/lavague-qa/features/demo_wikipedia.feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j86Dxofyxzmx",
        "outputId": "d50674e1-4230-4b74-e39f-dfe260dba89c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature: Wikipedia Login\n",
            "\n",
            "  Scenario: User logs in successfully\n",
            "    Given the user is on the Wikipedia homepage\n",
            "    When the user navigates to the login page\n",
            "    And the user enters Lavague-test in the username field\n",
            "    And the user enters lavaguetest123 in the password field\n",
            "    And the user clicks on login under the username and password field\n",
            "    Then the login is successful and the user is redirected to the main page\n"
          ]
        }
      ],
      "source": [
        "!cat demo_wikipedia.feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpQQiMJfxqWy"
      },
      "source": [
        "# 2. Run LaVague QA\n",
        "\n",
        "LaVague QA is a CLI tool, as such, we run it with `!` in notebooks.\n",
        "\n",
        "We will run in `--headless` mode since colab cannot display a browser window. LaVague will run all steps defined in your tests and record actions and selectors. If you're running locally, you can remove this flag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3PQURTSfT-A",
        "outputId": "1c58d796-9fe9-406f-8ff6-39ce6ba7d8fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /usr/local/lib/python3.10/dist-\n",
            "[nltk_data]     packages/llama_index/legacy/_static/nltk_cache...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /usr/local/lib/python3.10/dist-\n",
            "[nltk_data]     packages/llama_index/legacy/_static/nltk_cache...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/lavague/core/__init__.py:21: UserWarning: \u001b[93mTelemetry is turned on. To turn off telemetry, set your LAVAGUE_TELEMETRY to 'NONE'\u001b[0m\n",
            "  warnings.warn(warning_message, UserWarning)\n",
            "Ready to generate tests on https://en.wikipedia.org/ for Feature: Wikipedia Login\n",
            "\n",
            "  Scenario: User logs in successfully\n",
            "    Given the user is on the Wikipedia homepage\n",
            "    When the user navigates to the login page\n",
            "    And the user enters Lavague-test in the username field\n",
            "    And the user enters lavaguetest123 in the password field\n",
            "    And the user clicks on login under the username and password field\n",
            "    Then the login is successful and the user is redirected to the main page\n",
            "\n",
            "2024-08-05 07:11:55,274 - INFO - Screenshot folder cleared\n",
            "2024-08-05 07:12:00,389 - INFO - Thoughts:\n",
            "- The current screenshot shows the main page of Wikipedia.\n",
            "- The objective is to navigate to the login page.\n",
            "- Wikipedia typically has a 'Log in' link at the top right corner of the page.\n",
            "- The next step should involve clicking on the 'Log in' link to navigate to the login page.\n",
            "\n",
            "Next engine: Navigation Engine\n",
            "Instruction: Click on the 'Log in' link at the top right corner of the page.\n",
            "2024-08-05 07:12:05,627 - ERROR - Navigation error: No element found.\n",
            "2024-08-05 07:12:07,751 - ERROR - Navigation error: No element found.\n",
            "2024-08-05 07:12:11,813 - ERROR - Navigation error: No element found.\n",
            "2024-08-05 07:12:13,841 - ERROR - Navigation error: No element found.\n",
            "2024-08-05 07:12:15,968 - ERROR - Navigation error: No element found.\n",
            "2024-08-05 07:12:19,780 - INFO - Thoughts:\n",
            "- The current screenshot shows the Wikipedia homepage with a pop-up about Wikipedia's new colors.\n",
            "- The previous instruction to click on the 'Log in' link at the top right corner of the page failed.\n",
            "- The pop-up might be obstructing the 'Log in' link, preventing the click action from succeeding.\n",
            "- The next step should involve closing the pop-up to access the 'Log in' link.\n",
            "\n",
            "Next engine: Navigation Engine\n",
            "Instruction: Click on the 'X' button to close the pop-up about Wikipedia's new colors.\n",
            "2024-08-05 07:12:30,628 - INFO - Thoughts:\n",
            "- The current screenshot shows the main page of Wikipedia.\n",
            "- The previous step was to close the pop-up about Wikipedia's new colors, which has been successfully done.\n",
            "- The objective is to enter 'lavaguetest123' in the password field.\n",
            "- The next step is to navigate to the login page to find the password field.\n",
            "\n",
            "Next engine: Navigation Engine\n",
            "Instruction: Click on the 'Log in' link at the top right corner of the page.\n",
            "2024-08-05 07:12:40,619 - INFO - Thoughts:\n",
            "- The current screenshot shows the login page of Wikipedia.\n",
            "- The objective is to click on the 'Log in' button under the username and password fields.\n",
            "- The 'Log in' button is clearly visible and can be interacted with.\n",
            "\n",
            "Next engine: Navigation Engine\n",
            "Instruction: Click on the 'Log in' button under the username and password fields.\n",
            "2024-08-05 07:12:51,043 - INFO - Thoughts:\n",
            "- The current screenshot shows the login page of Wikipedia.\n",
            "- The previous instruction to click on the 'Log in' button under the username and password fields was executed.\n",
            "- The login attempt failed because the username and password fields were not filled out.\n",
            "- To successfully log in, the username and password fields need to be filled with valid credentials before clicking the 'Log in' button again.\n",
            "\n",
            "Next engine: Navigation Engine\n",
            "Instruction: Enter a valid username in the 'Username' field and a valid password in the 'Password' field, then click on the 'Log in' button.\n",
            "Scenario might not be completed\n",
            "◠\u001b[0m Generating pytest...Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/lavague-qa\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lavague/qa/cli.py\", line 78, in cli\n",
            "    pytest_generator.generate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lavague/qa/generator.py\", line 116, in generate\n",
            "    code = self._build_pytest_file(logs, assert_code)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lavague/qa/generator.py\", line 196, in _build_pytest_file\n",
            "    pytest_code += self._generate_when_steps(logs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lavague/qa/generator.py\", line 216, in _generate_when_steps\n",
            "    when_steps += self._get_pytest_when(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lavague/qa/generator.py\", line 229, in _get_pytest_when\n",
            "    \"\\n\".join([INDENT + get_nav_action_code(a[\"action\"]) for a in actions])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lavague/qa/generator.py\", line 229, in <listcomp>\n",
            "    \"\\n\".join([INDENT + get_nav_action_code(a[\"action\"]) for a in actions])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lavague/qa/utils.py\", line 61, in get_nav_action_code\n",
            "    args = action[\"args\"]\n",
            "KeyError: 'args'\n",
            "◝\u001b[0m Generating pytest..."
          ]
        }
      ],
      "source": [
        "!lavague-qa --headless --url https://en.wikipedia.org/ --feature ./demo_wikipedia.feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qiFeTZcxqZW"
      },
      "source": [
        "We now display the pytest file generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJq8GqrWxyzz"
      },
      "outputs": [],
      "source": [
        "!cat generated_tests/demo_wikipedia.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q22_gCb0nyJ"
      },
      "source": [
        "## Run the following cell if in colab, otherwise you can skip this cell.\n",
        "\n",
        "Since colab only allows headless browsers, we need to inject a `--headless` argument to our pytest fixture before we start the brower driver.\n",
        "\n",
        "This cell opens the file, replaces the code and writes the file back to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9EVUcKJqiuo"
      },
      "outputs": [],
      "source": [
        "FILE_PATH = \"generated_tests/demo_wikipedia.py\"\n",
        "\n",
        "REPLACEMENT = (\n",
        "\"\"\"from selenium.webdriver.chrome.options import Options\n",
        "    from selenium import webdriver\n",
        "    options = Options()\n",
        "    options.add_argument(\"--headless\")\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    driver = webdriver.Chrome(options=options)\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "# read file\n",
        "with open(FILE_PATH, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "modified_content = content.replace(\"driver = webdriver.Chrome()\", REPLACEMENT)\n",
        "\n",
        "# write file\n",
        "with open(FILE_PATH, 'w') as file:\n",
        "    file.write(modified_content)\n",
        "\n",
        "print(f\"Updated file: {FILE_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG4Jfg4CxVoL"
      },
      "source": [
        "Let's look at the file after injecting a new fixture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1jnT_SPrvBO"
      },
      "outputs": [],
      "source": [
        "!cat generated_tests/demo_wikipedia.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TqmM0ot1f9G"
      },
      "source": [
        "# Run the tests\n",
        "\n",
        "We can now run tests using `pytest`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfI9D57IgIvp"
      },
      "outputs": [],
      "source": [
        "!pytest generated_tests/demo_wikipedia.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
